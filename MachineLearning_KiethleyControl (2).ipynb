{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pyMez import *\n",
    "from pyMez.Code.Analysis.SParameter import *\n",
    "from pyMez.Code.DataHandlers.NISTModels import *\n",
    "from pyMez.Code.DataHandlers.Translations import *\n",
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "#from Machine_Learning import *\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up the Dictionary System and opening the files needed to train the classifer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device_type_dictionary={0:\"3.3KOhms\",1:\"3.6KOhms\",2:\"3.9KOhms\",3:\"100KOhms\",4:\"200KOhms\",\n",
    "                        5:\"ZenerDiode\",6:\"GreenLED\"}\n",
    "pretrain_folder=r\"C:\\Users\\msh7\\Desktop\\KiethleyControl\"\n",
    "pretrain_files=os.listdir(pretrain_folder)\n",
    "pretrain_files=map(lambda x:os.path.join(pretrain_folder,x),pretrain_files) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function that creates the training arrays (increases the number of training sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_xml_training_set(pretrain_folder,number_training_sets=1000,expansion_factor=1):\n",
    "    \"\"\"Given a directory containing multiple measurements this creates a list of np.arrays to \n",
    "    train a classifier\"\"\"\n",
    "    pretrain_files=os.listdir(pretrain_folder)\n",
    "    pretrain_files=map(lambda x:os.path.join(pretrain_folder,x),pretrain_files)\n",
    "    # now open the files convert them to AsciiData Tables and find the mean and standard deviation\n",
    "    first_file=XmlDataTable_to_AsciiDataTable((DataTable(pretrain_files[0])))\n",
    "    joined_file=first_file.copy()\n",
    "    for file_name in pretrain_files[1:]:\n",
    "        joined_file=joined_file+XmlDataTable_to_AsciiDataTable(DataTable(file_name))\n",
    "    #replaces the column Index with Frequency \n",
    "    joined_file.column_names=map(lambda x: x.replace(\"Index\",\"Frequency\"),joined_file.column_names)\n",
    "    #Turns the columns into floats \n",
    "    joined_file.options[\"column_types\"] = [\"float\" for i in joined_file.column_names]\n",
    "    joined_file.data=[[float(joined_file.data[j][i]) for i in range(len(row))] for j,row in enumerate(joined_file.data[:])]\n",
    "    mean_file=frequency_model_collapse_multiple_measurements(joined_file)\n",
    "    std_file=frequency_model_collapse_multiple_measurements(joined_file,\n",
    "                                                            method=\"std\")\n",
    "    #calucates the mean and standard deviation \n",
    "    mean_array=np.array(mean_file[\"Current\"])\n",
    "    std_array=np.array(std_file[\"Current\"])\n",
    "    #increases the number of training arrays \n",
    "    training_arrays=np.array([np.random.normal(loc=mean_value,scale=expansion_factor*std_array[index]+.0001,\n",
    "                                               size=number_training_sets) for index,\n",
    "                              mean_value in enumerate(mean_array)])\n",
    "    #reorganizes the training arrays \n",
    "    training_arrays=[[training_arrays[i][j] \n",
    "                      for i in range(len(mean_array))] for j in range(number_training_sets)]\n",
    "    return training_arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trains each individual device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set33=create_xml_training_set(r\"C:\\Users\\msh7\\Desktop\\KiethleyControl\\resistor_3.3kohm\")\n",
    "training_set36=create_xml_training_set(r\"C:\\Users\\msh7\\Desktop\\KiethleyControl\\resistor_3.6kohm\")\n",
    "training_set39=create_xml_training_set(r\"C:\\Users\\msh7\\Desktop\\KiethleyControl\\resistor_3.9kohm\")\n",
    "training_set100=create_xml_training_set(r\"C:\\Users\\msh7\\Desktop\\KiethleyControl\\resistor_100Kohm\")\n",
    "training_set200=create_xml_training_set(r\"C:\\Users\\msh7\\Desktop\\KiethleyControl\\resistor_200Kohm\")\n",
    "training_set_zener=create_xml_training_set(r\"C:\\Users\\msh7\\Desktop\\KiethleyControl\\diode_zener\")\n",
    "training_set_green=create_xml_training_set(r\"C:\\Users\\msh7\\Desktop\\KiethleyControl\\diode_greenLED\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adds all the individual training sets into one single array to train the classifer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_array = []\n",
    "training_array = training_set33+ training_set36 +training_set39+training_set100+training_set200+training_set_zener+ training_set_green"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots the training set of an individual device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    plt.plot(training_set)\n",
    "plt.show\n",
    "\n",
    "\n",
    "for training_set in training_set36:\n",
    "    plt.plot(training_set)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creates the target array that matches each device measurement with the corresponding number from the dictionary. Ex. 3.3KOhms measurements are all 0s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_training_sets=1000\n",
    "expansion_factor=1\n",
    "sorted_device_keys=sorted(device_type_dictionary.keys())\n",
    "target_array=[]\n",
    "for key_index,key in enumerate(sorted_device_keys):\n",
    "    target_array=target_array+[key for i in range(number_training_sets)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trains the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 6, 6, 6])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier=QuadraticDiscriminantAnalysis()\n",
    "classifier.fit(training_array,target_array)\n",
    "classifier.predict(training_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "160"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_array[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['100KOhms']\n"
     ]
    }
   ],
   "source": [
    "xml = DataTable(r\"C:\\Users\\msh7\\Desktop\\Hola\\1234.xml\")\n",
    "test_file = XmlDataTable_to_AsciiDataTable(xml)\n",
    "test_array = [np.array(test_file[\"Current\"], dtype = float)]\n",
    "\n",
    "predictions=classifier.predict(test_array)\n",
    "devices=[device_type_dictionary[key] for key in predictions.tolist()]\n",
    "print(devices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PICKLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_out = open(\"MachineLearning.pickle\", \"wb\")\n",
    "pickle.dump(classifier, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_in = open(\"MachineLearning.pickle\", \"rb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=classifier.predict(test_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ZenerDiode']\n"
     ]
    }
   ],
   "source": [
    "devices=[device_type_dictionary[key] for key in predictions.tolist()]\n",
    "print(devices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
